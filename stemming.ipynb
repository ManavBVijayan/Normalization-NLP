{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12a3ef11-fbb7-43e2-ac36-10f32035152b",
   "metadata": {},
   "source": [
    "###### Porter stemmer Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20f25f85-d180-41c8-91b2-b41c282c373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc787f5f-72f1-4d41-8bdd-98a533dfe934",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bee2e2de-066a-43f8-8dd9-8fa19ee3be48",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rafting\", \"ability\", \"meeting\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baf9825d-713f-4d00-9252-4fc7105f279c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat\n",
      "eat\n",
      "eat\n",
      "ate\n",
      "adjust\n",
      "raft\n",
      "abil\n",
      "meet\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(porter.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acb2df21-ea83-4c62-8707-0719688604af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case of sentences we have to do tokenization\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28dc5ded-94f0-4167-b301-ab38f1e49572",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Tokenization is an important step in natural language processing.\"\n",
    "words=word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65cf606b-18ed-45d7-acc7-5ab8d2e4c41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tokenization',\n",
       " 'is',\n",
       " 'an',\n",
       " 'important',\n",
       " 'step',\n",
       " 'in',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc29ae25-3cbe-4dd5-801e-5073cbfda39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words = [porter.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08285eb1-32a0-47af-93f0-d6af6471e75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['token',\n",
       " 'is',\n",
       " 'an',\n",
       " 'import',\n",
       " 'step',\n",
       " 'in',\n",
       " 'natur',\n",
       " 'languag',\n",
       " 'process',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8329e1b2-0258-461f-b675-542fb8abf483",
   "metadata": {},
   "source": [
    "###### Snowball Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1eb0baf3-3f3a-4c1f-a13b-f9e0bfcc717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d125f59-cf61-46f2-94b6-e78da0847295",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball=SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaf66fbf-a528-4fdb-a684-638bf2eed5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rafting\", \"ability\", \"meeting\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f55e25f5-cf56-4a8a-9b4c-9d868a1a54c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words=[snowball.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20678417-e2dd-41f7-8481-bcbee1f37624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eat', 'eat', 'eat', 'ate', 'adjust', 'raft', 'abil', 'meet']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f2f691-e007-4158-a258-2815d794ffb4",
   "metadata": {},
   "source": [
    "###### Lancaster Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6262dfe0-35da-4b82-a8a6-6b4986c1bc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5da0f74b-f28f-4662-a0ff-d7eac839e382",
   "metadata": {},
   "outputs": [],
   "source": [
    "lancaster=LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac46da89-62bb-45cf-8960-47f1c26ef97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rafting\", \"ability\", \"meeting\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e137544a-ded5-4317-9c01-bfafa4f69ee5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eat', 'eat', 'eat', 'at', 'adjust', 'raft', 'abl', 'meet']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_words=[lancaster.stem(word) for word in words]\n",
    "stemmed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8c7f61-d389-4a8b-b458-d42132b7c8af",
   "metadata": {},
   "source": [
    "###### Customizing the Rule of stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c8606df-ff54-41e3-b6a4-d952239dce24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: Customization is possible with custom stemming rules.\n",
      "Stemmed Words: ['custom', 'is', 'possibl', 'with', 'custom', 'stem', 'rule', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Example sentence\n",
    "sentence = \"Customization is possible with custom stemming rules.\"\n",
    "\n",
    "# Create a PorterStemmer object\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# Define custom stemming rules\n",
    "custom_rules = {\"customization\": \"custom\", \"rules\": \"rule\"}\n",
    "\n",
    "# Tokenize the sentence into words\n",
    "words = word_tokenize(sentence)\n",
    "\n",
    "# Apply custom stemming rules before Porter Stemmer using a loop\n",
    "stemmed_words = []\n",
    "for word in words:\n",
    "    if word in custom_rules:\n",
    "        stemmed_words.append(custom_rules[word])\n",
    "    else:\n",
    "        stemmed_words.append(porter.stem(word))\n",
    "\n",
    "# Print the result\n",
    "print(\"Original Sentence:\", sentence)\n",
    "print(\"Stemmed Words:\", stemmed_words)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
